# ğŸ—„ï¸ LRU Cache â€” LLD

A generic, fixed-capacity **Least Recently Used (LRU) Cache** implemented from scratch using a `HashMap` + custom **Doubly Linked List** â€” achieving O(1) time complexity for both `get` and `put`.

---

## ğŸ§© Class Design

```
LRUCache<K, V>
â”œâ”€â”€ HashMap<K, CacheEntry<K,V>>    â† O(1) key lookup
â”œâ”€â”€ CacheEntry<K,V> head           â† sentinel (dummy head)
â””â”€â”€ CacheEntry<K,V> tail           â† sentinel (dummy tail)

        head â†” [MRU] â†” ... â†” [LRU] â†” tail
```

### Classes

| Class | Role |
|-------|------|
| `LRUCache<K, V>` | The cache. Generic over key and value types. Maintains a `HashMap` for O(1) lookup and a doubly linked list for O(1) access-order tracking. |
| `CacheEntry<K, V>` | A node in the doubly linked list. Holds `key`, `value`, `prev`, and `next` pointers. |

---

## âš™ï¸ Design Decisions

### Why HashMap + Doubly Linked List?
| Requirement | Solution |
|-------------|----------|
| O(1) lookup by key | `HashMap<K, CacheEntry>` |
| O(1) track & update access order | Doubly Linked List (move node to front on access) |
| O(1) evict LRU entry | Always `tail.prev` â€” remove in O(1) |

A singly linked list would require O(n) to find the previous node. A `LinkedHashMap` could do this too, but implementing it from scratch demonstrates the underlying mechanism.

### Sentinel Nodes
`head` and `tail` are **dummy sentinel nodes** (holding `null` key/value). They permanently anchor the list, eliminating all null checks in pointer manipulation:
```
head â†” [entry1 (MRU)] â†” [entry2] â†” [entry3 (LRU)] â†” tail
```

### Access-Order Maintenance
On every `get` or `put`, the accessed entry is moved to `head.next` (front = Most Recently Used). Eviction always removes `tail.prev` (back = Least Recently Used).

### Generic Design
`LRUCache<K, V>` works for any key/value types:
```java
LRUCache<Integer, String> cache = new LRUCache<>(3);
LRUCache<String, User>    cache = new LRUCache<>(100);
```

---

## ğŸ”„ Operations

### `get(key)` â†’ O(1)
```
1. cache.get(key) â†’ CacheEntry  (HashMap lookup)
2. moveToFront(entry)           (removeNode + addToFront)
3. return entry.value
```

### `put(key, value)` â†’ O(1)
```
1. cache.get(key)
   â†’ if exists: update value, moveToFront, return
2. if cache.size() == capacity:
       evictLeastRecentlyUsed()   â† remove tail.prev from list + map
3. newEntry = new CacheEntry(key, value)
4. cache.put(key, newEntry)
5. addToFront(newEntry)           â† insert after head
```

### Internal Pointer Operations
```java
removeNode(entry):
    entry.prev.next = entry.next
    entry.next.prev = entry.prev

addToFront(entry):
    entry.next = head.next
    entry.prev = head
    head.next.prev = entry
    head.next = entry
```

---

## ğŸ“Š Complexity Summary

| Operation | Time | Space |
|-----------|------|-------|
| `get` | O(1) | â€” |
| `put` | O(1) | â€” |
| Overall | â€” | O(capacity) |

---

## ğŸ§  Design Patterns Used

| Pattern | Where |
|---------|-------|
| **Doubly Linked List + HashMap** | Core data structure combination |
| **Sentinel Node** | `head` and `tail` dummy nodes simplify edge cases |
| **Generic Programming** | `LRUCache<K,V>` works with any types |

---

## ğŸ“ Source Files

```
src/main/java/org/example/
â”œâ”€â”€ LRUCache.java      â† Core cache: HashMap + DLL logic
â”œâ”€â”€ CacheEntry.java    â† DLL node: key, value, prev, next
â””â”€â”€ Main.java          â† Demo with get/put scenarios
```

## â–¶ï¸ Running

```bash
mvn compile exec:java -Dexec.mainClass="org.example.Main"
```
